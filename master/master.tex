\title{
  \textsc{Investigation Into Some Numeric Solutions to Volterra Integral Equations of the First Kind}
}
\author{
  \textsc{Jeff Wendling}
}
\date{\today}
\documentclass[11pt]{article}
\usepackage{amsfonts,amsmath,amssymb,amsbsy,amsthm}
\usepackage{latexsym,bm}
\usepackage{upgreek}
\usepackage{graphics,graphicx}
\usepackage{subfigure}
\usepackage{subfigmat}
\usepackage{psfrag}
\usepackage{url}
\usepackage[square,numbers,comma,sort&compress]{natbib}
\usepackage{listings}
\usepackage{lstlang0}
\usepackage{float}

%dont reposition tables
\restylefloat{table}
\lstset{language=Go, numbers=left, showspaces=false}
\numberwithin{equation}{section}
\theoremstyle{definition}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}[theorem]{Definition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{example}[theorem]{Example}

%% some macros

%macro for unnumbered aligned environments
\newcommand{\eq}[1]{\begin{align*}#1\end{align*}}

%macro for numbered equations
\newcommand{\eqn}[2]{
  \begin{equation}
    \label{#1}
    #2
  \end{equation}
}

%macro for referencing equations/theorems
\newcommand{\eqr}[1]{Equation (\ref{#1})}
\newcommand{\thr}[1]{Theorem (\ref{#1})}

\begin{document}
\maketitle
\begin{abstract}
I present a simple numerical scheme for evaluation volterra integral
equations of the first kind. I prove some simple results about
convergence and verify the results numerically. These results are
compared to a method by Lubich in cases where the domain is large.
\end{abstract}
\setcounter{tocdepth}{1}
\tableofcontents
\lstlistoflistings
%\listoffigures
\listoftables
\section{Description of Method}
We start with a convolution type equation
\eqn{base_convolution}{
  K \star x = f
}
and pick some upper time $T$ and discritize the interval $[0, T]$ with $N$
equally spaced points, $t_0 = 0, ..., t_N = T$. We approximate the solution $x$
as a linear combination of indicator functions $\chi_i$ where
\eqn{indicator_defn}{
  \chi_i(t)
  =
  \left\{
  \begin{array}{ll}
    1 & t_{i} < t \leq t_{i+1} , \\
    0 & \text{otherwise}
  \end{array}
  \right.
}
giving
\eqn{solution_approx}{
<<<<<<< HEAD
  x_N(t) = \sum_{i=0}^{N-1} c_i \chi_i(t)
=======
  x_N(t) = \sum_{i=0}^{N-1} c_i \chi_i(t)
>>>>>>> added some stuff for clarity and future results
}
Substituting \eqr{solution_approx} into \eqr{base_convolution} and cosidering
the value of the new convolution at time $t_n$, we find that
\begin{align}
\nonumber             (K \star x_N)(t_n)
                        &= \int_0^{t_n} K(t_n - s)x(s)\; ds \\
\nonumber               &= \int_0^{t_n} K(t_n - s) \sum_{i=0}^{N-1} c_i \chi_i(s)\; ds \\
\nonumber               &= \int_0^{t_n} K(t_n - s) \sum_{i=0}^{n-1} c_i \chi_i(s)\; ds \\
\label{scheme_before}   &= \sum_{i=0}^{n-1} c_i \int_{t_i}^{t_{i+1}} K(t_n - s)\; ds
\end{align}
Now notice that with a simple substitution $u = t_n - s$
\eqn{kernel_substitution}{
  \int_{t_i}^{t_{i+1}}K(t_n - s)\; ds = \int_{t_{n-i-1}}^{t_{n-i}} K(u) du
}
which leads to the definition
\eqn{kernel_integral}{
  K_i = \int_{t_i}^{t_{i+1}} K(s)\; ds
}
Using \eqr{kernel_substitution} and \eqr{kernel_integral} into \eqr{scheme_before}
gives
\begin{align}
\nonumber       \sum_{i=0}^{n-1} c_i \int_{t_i}^{t_{i+1}} K(t_n - s)\; ds
                  &= \sum_{i=0}^{n-1} c_i \int_{t_{n-i-1}}^{t_{n-i}} K(u)\; du\\
\label{scheme}    &= \sum_{i=0}^{n-1} c_i K_{n-i-1} = f_N(t_n)
\end{align}
where we define $f_N$ to agree with $f$ at every point $t_i$ for $i \in 1, ..., N$.
The inner points depend on the kernel $K$ so that we have the relation
\eqn{approx_relation}{
  K \star x_N = f_N
}
\eqr{scheme} leads us to a numerical scheme for solving the convolution. It is
an iterative scheme in that given the values $c_0, ..., c_{n-1}$ we can find
the value $c_n$ by
\eqn{specific_term}{
  c_nK_0 = f(t_{n+1}) - \sum_{i=0}^{n-1} c_i K_{n-i}
}
\section{Proof of Convergence}
In this section we prove convergence for the scheme given by \eqr{specific_term}.
We begin by stating some theorems about convolutions,
\begin{theorem}
  \label{convolution_exists}
  $f \star g$ exists if $f \in L^1$, $g \in L^1$. When this is the case, $f \star g \in L^1$
\end{theorem}
\begin{proof}
The proof is given by Theorem 1.3 in \cite{stein71}
\end{proof}

\begin{theorem}
  \label{titchmarsh}
  If for $f \in L^1$, $g \in L^1$, $f \neq 0$ almost everywhere on $(0, T)$, and $f \star g = 0$ almost everywhere on $(0, T)$, then $g = 0$ almost everywhere on $(0, T)$.
\end{theorem}
\begin{proof}
This is a special case of the Titchmarsh convolution theorem given in \cite{titchmarsh}
\end{proof}

We begin with a theorem about the magnitude of the derivative of $f_N$.

\begin{theorem}
  \label{f_nderiv}
  If the kernel $K$ satisfies $|K(0)| < \infty$, $|K'(s)| < \infty$ for all $s \in [0, T]$,
  then 
$$
  |f_N'(s)|
  <
  \infty
$$
  for all $s \in [0, T)$.
\end{theorem}
\begin{proof}
Let $i$ be an index such that $|c_i| \geq |c_j|$ for all $j \in 0, ..., N-1$. Thus $|x_N| \leq |c_i|$.
Consider for some $x \in [0, T)$ and some $\epsilon > 0$,
\begin{align}
  \nonumber
  |f_N(x+\epsilon) - f_N(x)|
  &=
  \bigg|
  \int_0^{x+\epsilon} K(x+\epsilon - s)x_N(s)
  \; ds
  - \int_0^x K(x - s)x_N(s) 
  \; ds
  \bigg|
  \\
%
%
  \nonumber
  &=
  \bigg|
  \int_0^x \big(
    K(x+\epsilon - s) - K(x - s)
  \big)
  x_N(s)
  \; ds
  \\
  \nonumber
  &\quad
  \;
  + \int_x^{x+\epsilon} K(x+\epsilon-s)x_N(s)
  \; ds
  \bigg|
  \\
%
%
  \nonumber
  &\leq
  \int_0^x \epsilon C |c_i|
  \; ds
  + \int_{x}^{x+\epsilon} |K(x+\epsilon-s)x_N(s)|
  \; ds
  \\
%
%
  \nonumber
  \frac{1}{\epsilon}
  |f_N(x+\epsilon) - f_N(x)|
  &\leq
  TC|c_i| + 
  |c_i|
  \frac{1}{\epsilon}
  \int_x^{x+\epsilon} |K(x+\epsilon - s)|
  \; ds
  \\
%
%
  \nonumber
  &\leq
  TC|c_i|
  +
  |c_i|
  \frac{1}{\epsilon}
  \int_0^\epsilon |K(u)|
  \; du
  \\
%
%
  \nonumber
  &\leq
  |c_i|\Big(
    TC
    + \sup_{x\in[0, \epsilon]} |K(x)|
  \Big)
\end{align}
Taking the limit as $\epsilon \rightarrow 0$, we see that for all $x \in [0, T)$,
$$
  |f_N'(x)|
  \leq
  |c_i|\Big(
    TC
    + |K(0)|
  \Big)
$$
\end{proof}

We now state a result about the convergence of $f_N$ to $f$ as $N \rightarrow \infty$.

\begin{theorem}
  \label{f_dist_bound}
  If there exists some $M$ such that $|f'(x)| < M$ for all $x \in [0, T]$,
  and the hypotheses in \thr{f_nderiv} hold,
  then there exists some constant $C$ such that for all $s \in [0, T)$,
  $$
    |f(s) - f_N(s)|
    \leq
    hC
  $$
  where $h$ denotes the stepsize, $h = T/N$.
\end{theorem}
\begin{proof}
First we note that by the definition of $f_N$, for all $t_i$,
\eqn{f_ndefin_relation}{
  f_N(t_i) = f(t_i).
}
Now let $x \in [0, T]$ and pick $n$, $\epsilon$ such that
$$
  x = t_n + \epsilon
  \qquad
  \text{where}
  \qquad
  t_n \leq x < t_n+1
  \qquad
  \text{and}
  \qquad
  0 \leq \epsilon < h
$$
and consider
\eq{
  |f(x) - f_N(x)| &= |f(t_n + \epsilon) - f_N(t_n + \epsilon)| \\
  &= |f(t_n + \epsilon) - f(t_n) + f_N(t_n) - f_N(t_n + \epsilon)| \\
  &\leq |f(t_n + \epsilon) - f(t_n)| + |f_N(t_n) - f_N(t_n + \epsilon)| \\
  &\leq \epsilon (M + G) \\
  &\leq h(M + G)
}
where $G$ is given by \thr{f_nderiv}.
\end{proof}

We use \thr{f_dist_bound} to prove the $L^1$ convergence of $f_N \rightarrow f$.

\begin{theorem}
  \label{f_convergence}
  If the hypotheses hold in \thr{f_dist_bound} and \thr{f_nderiv} hold,
  then we have that
$$
  || f - f_N ||_1 \leq h C
$$
  for some constant $C$.
\end{theorem}
\begin{proof}
\eq{
  || f - f_N || _1
  &=
  \int_0^T |f(x) - f_N(x) |
  \; dx
  \\
%
%
  &= 
  \sum_{i=0}^{N-1} \int_{t_i}^{t_{i+1}}
  |f(x) - f_N(x)|
  \; dx
  \\
%
%
  &=
  \sum_{i=0}^{N-1}
  \int_0^h |f(t_i + s) - f_N(t_i + s)|
  \; ds
  \\
%
%
  &\leq
  \sum_{i=0}^{N-1}
  \int_0^h hC
  \; ds
  \\
%
%
  &\leq
  Nh^2 C
  =
  hTC
}
\end{proof}
Now we show convergence.
\begin{theorem}
  \label{convergence}
  If the hypotheses of \thr{f_convergence} hold,
  then we have that
$$
  ||x - x_N||_1
  \leq
  hC
$$
  for some constant $C$.
\end{theorem}
\begin{proof}
\end{proof}

\section{Sample Code}
\lstset{caption=Basic Scheme}
\lstinputlisting{conv/conv.go}
\lstset{caption=Lubich Scheme}
\lstinputlisting{lubich/lubich.go}
Please refer to table \ref{some_table} for some results.
\section{Numerical Results}
Some results are listed below.
\begin{table}[H]
  \caption{Error in $L^2$ vs stepsize}
  \label{some_table}
  \begin{center}
  \begin{tabular}{|c|c|}
  \hline
  Stepsize & Error \\ \hline
  .1 & $6e^{-7}$ \\ \hline
  .01 & $6e^{-8}$ \\ \hline
  .001 & $6e^{-9}$ \\ \hline
  .0001 & $6e^{-10}$ \\
  \hline
  \end{tabular}
  \end{center}
\end{table}
foo bar
\begin{table}[H]
  \caption{Error in $L^2$ vs stepsize}
  \label{some_table_2}
  \begin{center}
  \begin{tabular}{|c|c|}
  \hline
  Stepsize & Error \\ \hline
  .1 & $6e^{-7}$ \\ \hline
  .01 & $6e^{-8}$ \\ \hline
  .001 & $6e^{-9}$ \\ \hline
  .0001 & $6e^{-10}$ \\
  \hline
  \end{tabular}
  \end{center}
\end{table}
:()
\begin{table}[H]
  \caption{Error in $L^2$ vs stepsize}
  \label{some_table_3}
  \begin{center}
  \begin{tabular}{|c|c|}
  \hline
  Stepsize & Error \\ \hline
  .1 & $6e^{-7}$ \\ \hline
  .01 & $6e^{-8}$ \\ \hline
  .001 & $6e^{-9}$ \\ \hline
  .0001 & $6e^{-10}$ \\
  \hline
  \end{tabular}
  \end{center}
\end{table}
Always put a blank space after a table.

\bibliographystyle{alpha}
\bibliography{master}
\end{document}