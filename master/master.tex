\title{
  \textsc{Investigation Into Some Numeric Approximations to Volterra Integral Equations of the First Kind}
}
\author{
  \textsc{Jeff Wendling}
}
\date{\today}
\documentclass[11pt]{article}
\usepackage{amsfonts,amsmath,amssymb,amsbsy,amsthm}
\usepackage{latexsym,bm}
\usepackage{upgreek}
\usepackage{graphics,graphicx}
\usepackage{subfigure}
\usepackage{subfigmat}
\usepackage{psfrag}
\usepackage{url}
\usepackage[square,numbers,comma,sort&compress]{natbib}
\usepackage{listings}
\usepackage{lstlang0}
\usepackage{float}

%dont reposition tables
\restylefloat{table}
\lstset{language=Go, numbers=left, showspaces=false}
\numberwithin{equation}{section}
\theoremstyle{definition}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}[theorem]{Definition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{example}[theorem]{Example}

%% some macros

%macro for unnumbered aligned environments
\newcommand{\eq}[1]{\begin{align*}#1\end{align*}}

%macro for numbered equations
\newcommand{\eqn}[2]{
  \begin{equation}
    \label{#1}
    #2
  \end{equation}
}

%macro for referencing equations/theorems
\newcommand{\eqr}[1]{Equation (\ref{#1})}
\newcommand{\thr}[1]{Theorem (\ref{#1})}

\begin{document}
\maketitle
\begin{abstract}
In this paper a series of numerical methods for Volterra integral equations of
the first kind are discussed, implemented, and compared. The methods are the
scheme by Lubich, two discussed by Linz and one by myself.
\end{abstract}
\setcounter{tocdepth}{2}
\tableofcontents
\lstlistoflistings
%\listoffigures
\listoftables
\section{Description of Methods}
Throughout this paper, we assume as in \cite{linz}
\begin{description}
\item[(a)] $f(0) = 0$
\item[(b)] $K(0) \neq 0$
\item[(c)] $K$ and $f$ are bounded and sufficiently smooth for the rest of the 
analysis to work.
\end{description}
\subsection{Rectangular}
As discussed in \cite{linz}, we perform the simplest approximation to the equation
\eqn{rect_base}{
  \int_0^t K(t - s)x(s)\; ds = f(t)
}
First, as will become standard procedure, we pick an upper value $T$ and partition
it into $N+1$ equal intervals of width $h$ such that $t_0 = 0, ..., t_N = T$. Now
on each interval, we replace the kernel by it's left endpoint, so that
$$
  K_i = K(t_i) = K(hi)
$$
$$
  x_i = x(t_i) = x(hi)
$$
This leads to the equation at time $t_n$
\begin{eqnarray}
\nonumber              \int_0^{t_n} K(t_n - s)x(s)\; ds = f(t_n) \\
\label{before_approx}  \sum_{i=0}^{n=1} K_{n-i} \int_{t_i}^{t_{i+1}} x(s)\; ds = f(t_n)
\end{eqnarray}
We take a first order approximation of the integral term in \eqr{before_approx}
to get the equation
\eqn{rect_discrete}{
  h\sum_{i=0}^{n-1} K_{n-i} x_i = f(t_n)
}
We can create a numerical scheme from this by noticing that the value of $x(t_{n-1})$
is given by
\begin{eqnarray}
\nonumber            h \sum_{i=0}^{n-1} K_{n-i} x_i = f_n \\
\nonumber            x_{n-1} K_1 h + h\sum_{i=0}^{n-2} K_{n-i}x_i = f_n \\
\label{rect_scheme}  x_{n-1} = \frac{f_n}{K_1 h} - \frac{1}{K_1} \sum_{i=0}^{n-2} K_{n-i} x_i
\end{eqnarray}
Notice that the value of $x_{n-1}$ in \eqr{rect_scheme} depends only on the previous
values $x_0, ..., x_{n-2}$. Thus, we have an iterative scheme.
\subsection{Midpoint}
In the previous scheme, we picked the approximation of the kernel at the left endpoint.
A simple question to ask is if a different point in the interval would give better
accuracy. It turns out there is such a point. As discussed in \cite{linz} using
the midpoint of the interval gives better accuracy. If we define
$$
  K_{i} = K(hi)
$$
$$
  x_{i} = x(hi)
$$
and considering \eqr{rect_base} at time $t_n$ again, we find
\begin{eqnarray}
\nonumber              \int_0^{t_n} K(t_n - s)x(s)\; ds = f(t_n) \\
\label{mid_before_approx}  \sum_{i=0}^{n=1} K_{n-i-1/2} \int_{t_i}^{t_{i+1}} x(s)\; ds = f(t_n)
\end{eqnarray}
We take a first order approximation of the integral term at the midpoint in
\eqr{mid_before_approx} to get the equation
\eqn{mid_discrete}{
  h\sum_{i=0}^{n-1} K_{n-i-1/2} x_{i+1/2} = f(t_n)
}
We can create a numerical scheme from this by noticing that the value of $x(t_{n-1/2})$
is given by
\begin{eqnarray}
\nonumber            h \sum_{i=0}^{n-1} K_{n-i-1/2} x_{i+1/2} = f_n \\
\nonumber            x_{n-1/2} K_{1/2} h + h\sum_{i=0}^{n-2} K_{n-i-1/2}x_{i+1/2} = f_n \\
\label{mid_scheme}  x_{n-1/2} = \frac{f_n}{K_{1/2} h} - \frac{1}{K_{1/2}} \sum_{i=0}^{n-2} K_{n-i-1/2} x_{i+1/2}
\end{eqnarray}
Notice that the value of $x_{n-1/2}$ in \eqr{mid_scheme} depends only on the previous
values $x_{1/2}, ..., x_{n-3/2}$. Thus, we have an iterative scheme.

\subsection{Exact Kernel}
We attempt to exploit the symmetry in convolutions, 
$$
  K \star x = x \star K
$$
assuming that we know the exact integral form of the kernel. This allows us to
approximate our solution as constant over each interval and instead of being forced
to approximate the integral of the kernel as a point inside the interval, we can
use the exact value, hoping for higher order accuracy.
We start with a convolution type equation
\eqn{base_convolution}{
  K \star x = f
}
and pick some upper time $T$ and discretize the interval $[0, T]$ with $N+1$
equally spaced points, $t_0 = 0, ..., t_N = T$. We approximate the solution $x$
as a linear combination of indicator functions $\chi_i$ where
\eqn{indicator_defn}{
  \chi_i(t)
  =
  \left\{
  \begin{array}{ll}
    1 & t_{i} \leq t < t_{i+1} , \\
    0 & \text{otherwise}
  \end{array}
  \right.
}
giving
\eqn{solution_approx}{
  x_N(t) = \sum_{i=0}^{N-1} c_i \chi_i(t)
}
Substituting \eqr{solution_approx} into \eqr{base_convolution} and cosidering
the value of the new convolution at time $t_n$, we find that
\begin{align}
\nonumber             f(t_n) = (K \star x_N)(t_n)
                        &= \int_0^{t_n} K(t_n - s)x_N(s)\; ds \\
\nonumber               &= \int_0^{t_n} K(t_n - s) \sum_{i=0}^{N-1} c_i \chi_i(s)\; ds \\
\nonumber               &= \int_0^{t_n} K(t_n - s) \sum_{i=0}^{n-1} c_i \chi_i(s)\; ds \\
\label{scheme_before}   &= \sum_{i=0}^{n-1} c_i \int_{t_i}^{t_{i+1}} K(t_n - s)\; ds
\end{align}
Now notice that with a simple substitution $u = t_n - s$
\eqn{kernel_substitution}{
  \int_{t_i}^{t_{i+1}}K(t_n - s)\; ds = \int_{t_{n-i-1}}^{t_{n-i}} K(u) du
}
which leads to the definition
\eqn{kernel_integral}{
  K_i = \int_{t_i}^{t_{i+1}} K(s)\; ds
}
Using \eqr{kernel_substitution} and \eqr{kernel_integral} into \eqr{scheme_before}
gives
\begin{align}
\nonumber       \sum_{i=0}^{n-1} c_i \int_{t_i}^{t_{i+1}} K(t_n - s)\; ds
                  &= \sum_{i=0}^{n-1} c_i \int_{t_{n-i-1}}^{t_{n-i}} K(u)\; du\\
\label{scheme}    &= \sum_{i=0}^{n-1} c_i K_{n-i-1} = f(t_n)
\end{align}
\eqr{scheme} leads us to a numerical scheme for solving the convolution. It is
an iterative scheme in that given the values $c_0, ..., c_{n-1}$ we can find
the value $c_n$ by
\eqn{specific_term}{
  c_nK_0 = f(t_{n+1}) - \sum_{i=0}^{n-1} c_i K_{n-i}
}
Because this method gives a value of $x$ for the entire interval $[0,T]$ while the
other methods just give values at a point inside each subinterval, we will
choose to use the value at a midpoint of each subinterval, $t_{n+1/2}$, for
purposes of comparing accuracy.
\subsection{Lubich}
The Lubich scheme is the one discussed in \cite{lubich}. We will use the simplest
case of linear multistep method, Backward Euler. If we use a hat to denote Laplace
transform, we can approximate the convolution
$$
  \int_0^t K(s) x(t - s)\; ds
$$
by picking a stepsize $h$ and our approximation is
\eqn{lubich_approx}{
  \sum_{0 \leq ih \leq t} \omega_j(h) x(t - jh)
}
where $\omega_n$ is given by
\eqn{lubich_omega}{
  \hat{K}\left(\frac{\delta(z)}{h}\right) = \sum_{n=0}^\infty \omega_n(h) z^n
}
and $\delta(z) = 1-z$, the generating polynomial of the Backward Euler method.
This can be used to create an iterative scheme by considering the approximation
at time $t_n$. We have from \eqr{lubich_approx}
\begin{align}
\nonumber  f(t_n)
                  &= \int_0^{t_n} K(s) x(t_n - s)\; ds \\
                  &= \sum_{i=0}^{n} \omega_i(h) x_{n-i}
\end{align}
Thus we have
\eqn{lubich_scheme}{
  x_n \omega_0 = f_n - \sum_{i=1}^n \omega_i(h) x_{n-i}
}
where the right hand side depends only on terms $x_0, ..., x_{n-1}$.
\section{Numerical Results}
We will compare these four numerical methods against each other with known solutions.
A set of three kernels and three functions will be used giving a total of nine tests.
The three kernels are $e^{-t}$, $\cosh(t)$ and $t^{-1/2}$. The three functions we
will use for testing will be $te^{-t}$, $t^3$, and $\sin t$.
\subsection{Exact Solutions}
The solutions for these kernels given
that $f(0) = 0$ is given by \cite{handbook} and \cite{abel} as
\begin{align}
\label{kernel1_soln}  e^{-t} &\implies f'(t) + f(t) \\
\label{kernel2_soln} \cosh(t) &\implies f'(t) - \int_0^t f(s) \; ds \\
\label{kernel3_soln} t^{-1/2} &\implies \frac{1}{\pi}\frac{d}{dt}\int_0^t \frac{f(s) \; ds}{\sqrt{t - s}}
\end{align}
A table of the exact solutions is given below. The functions $F$, $C$, and $S$ are
the Dawson Function and the Fresnel Integrals given as 
\begin{align}
\label{dawson}    F(t) &= e^{-t^2}\int_0^t e^{s^2}\; ds \\
\label{fresnel_c} C(t) &= \int_0^t \cos(s^2) \; ds \\
\label{fresnel_s} S(t) &= \int_0^t \sin(t^2) \; ds
\end{align}
\renewcommand{\arraystretch}{2.0}
\begin{table}[H]
  \caption{Exact Solutions}
  \label{exact_solutions}
  \begin{center}
  \begin{tabular}{|c|c|c|}
  \hline
  Kernel & Function & Solution \\ \hline
  $e^{-t}$ & $te^{-t}$ & $e^{-t}$ \\ \hline
  $e^{-t}$ & $t^3$ & $3t^2 + t^3$ \\ \hline
  $e^{-t}$ & $\sin t$ & $\sin t + \cos t$  \\ \hline
  $\cosh t$ & $te^{-t}$ & $2e^{-t} - 1$\\ \hline
  $\cosh t$ & $t^3$ & $3t^2 - \frac{1}{4}t^4$\\ \hline
  $\cosh t$ & $\sin t$ & $2\cos t - 1$\\ \hline
  $t^{-1/2}$ & $te^{-t}$ & $\sqrt{t} + (1-2t)F(\sqrt{t})$\\ \hline
  $t^{-1/2}$ & $t^3$ & $\dfrac{16 t^{5/2}}{5\pi}$\\ \hline
  $t^{-1/2}$ & $\sin t$ & $\sqrt{\frac{2}{\pi}} \bigg(C\big(\sqrt{\frac{2t}{\pi}}\big) \cos t  + S\big(\sqrt{\frac{2t}{\pi}}\big)\sin t  \bigg)$\\
  \hline
  \end{tabular}
  \end{center}
\end{table}
\begin{table}[H]
  \caption{Error in $L^2$ vs stepsize}
  \label{some_table}
  \begin{center}
  \begin{tabular}{|c|c|}
  \hline
  Stepsize & Error \\ \hline
  .1 & $6e^{-7}$ \\ \hline
  .01 & $6e^{-8}$ \\ \hline
  .001 & $6e^{-9}$ \\ \hline
  .0001 & $6e^{-10}$ \\
  \hline
  \end{tabular}
  \end{center}
\end{table}
foo bar
\begin{table}[H]
  \caption{Error in $L^2$ vs stepsize}
  \label{some_table_2}
  \begin{center}
  \begin{tabular}{|c|c|}
  \hline
  Stepsize & Error \\ \hline
  .1 & $6e^{-7}$ \\ \hline
  .01 & $6e^{-8}$ \\ \hline
  .001 & $6e^{-9}$ \\ \hline
  .0001 & $6e^{-10}$ \\
  \hline
  \end{tabular}
  \end{center}
\end{table}
:()
\begin{table}[H]
  \caption{Error in $L^2$ vs stepsize}
  \label{some_table_3}
  \begin{center}
  \begin{tabular}{|c|c|}
  \hline
  Stepsize & Error \\ \hline
  .1 & $6e^{-7}$ \\ \hline
  .01 & $6e^{-8}$ \\ \hline
  .001 & $6e^{-9}$ \\ \hline
  .0001 & $6e^{-10}$ \\
  \hline
  \end{tabular}
  \end{center}
\end{table}
Always put a blank space after a table.


\newpage
\section{Sample Code}
\subsection{Rectangular}
\lstset{caption=Rectangular Scheme}
\lstinputlisting{src/rect/rect.go}
\newpage
\subsection{Midpoint}
\lstset{caption=Midpoint Scheme}
\lstinputlisting{src/mid/mid.go}
\newpage
\subsection{Exact Kernel}
\lstset{caption=Exact Kernel Scheme}
\lstinputlisting{src/exact/exact.go}
\newpage
\subsection{Lubich}
\lstset{caption=Lubich Scheme}
\lstinputlisting{src/lubich/lubich.go}
\newpage
\bibliographystyle{alpha}
\bibliography{master}
\end{document}